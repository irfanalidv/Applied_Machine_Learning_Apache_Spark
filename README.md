# Applied_Machine_Learning_Apache_Spark
Apache® Spark™ for Machine Learning and Data Science
                                                        

**Create and transform** 

- DataFrames to query large datasets.

https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6974851263301701/193175068117394/6267955876615859/latest.html

- Improve performance through judicious use of caching and applying best practices.
- Visualize how jobs are broken into stages and tasks and executed within Spark.
- Troubleshoot errors and program crashes using Spark UI, executor logs, driver stack traces, and local-mode runtimes.
- Find answers to common Spark and Databricks questions using the documentation and other resources.

**Extracting, Processing, and Analyzing Data**

- Extract, transform, and load (ETL) data from multiple federated data sources (JSON, relational database, etc.) with DataFrames.
- Extract structured data from unstructured data sources by parsing using DataFrames/Datasets
- Extend the capabilities of DataFrames using user defined functions (UDFs and UDAFs) in Python and Scala.
- Resolve missing fields in DataFrame rows using filtering and imputation.
- Apply best practices for data analytics using Spark
- Perform exploratory data analysis (EDA) using DataFrames and Datasets to:
    - Compute descriptive statistics.
    - Identify data quality issues.
    - Better understand a dataset.

**Visualizing Data**

- Use the Databricks platform to create visualizations within the notebook.

**Machine Learning**

- Build machine learning pipelines for both supervised and unsupervised learning.
- Train analytical models with Spark ML’s DataFrame-based estimators including: linear regression, logistic regression, decision trees, K-nearest neighbors, Boosted Trees, Alternating Least Squares, Neural Nets, and text classification.
- Use Spark ML transformers to perform pre-processing on a dataset prior to training, including: standardization, normalization, one-hot encoding, and binarization.
- Create Spark ML pipelines to create a processing pipeline including transformations, estimations, evaluation of analytical models.
- Evaluate model accuracy with cross validation, ROC curves, and RSME.
- Tune training hyper-parameters by integrating cross-validation and grid search into Spark ML Pipelines.
- Troubleshoot and tune machine learning algorithms in Spark
