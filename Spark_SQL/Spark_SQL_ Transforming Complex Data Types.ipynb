{"cells":[{"cell_type":"code","source":["from pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n\n# Convenience function for turning JSON strings into DataFrames.\ndef jsonToDataFrame(json, schema=None):\n  # SparkSessions are available with Spark 2.0+\n  reader = spark.read\n  if schema:\n    reader.schema(schema)\n  return reader.json(sc.parallelize([json]))"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Selecting from nested columns - Dots (\".\") can be used to access nested columns for structs and maps.\n\n# Using a struct\nschema = StructType().add(\"a\", StructType().add(\"b\", IntegerType()))\n                                \nevents = jsonToDataFrame(\"\"\"\n{\n  \"a\": {\n     \"b\": 1\n  }\n}\n\"\"\", schema)\n\ndisplay(events.select(\"a.b\"))"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Using a map\nschema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n                          \nevents = jsonToDataFrame(\"\"\"\n{\n  \"a\": {\n     \"b\": 1\n  }\n}\n\"\"\", schema)\n\ndisplay(events.select(\"a.b\"))"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["<b>Flattening structs</b> - A star (`\"*\"`) can be used to select all of the subfields in a struct."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": {\n     \"b\": 1,\n     \"c\": 2\n  }\n}\n\"\"\")\n\ndisplay(events.select(\"a.*\"))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["<b>Nesting columns</b> - The `struct()` function or just parentheses in SQL can be used to create a new struct."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": 1,\n  \"b\": 2,\n  \"c\": 3\n}\n\"\"\")\n\ndisplay(events.select(struct(col(\"a\").alias(\"y\")).alias(\"x\")))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["<b>Nesting all columns</b> - The star (`\"*\"`) can also be used to include all columns in a nested struct."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": 1,\n  \"b\": 2\n}\n\"\"\")\n\ndisplay(events.select(struct(\"*\").alias(\"x\")))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["<b>Selecting a single array or map element</b> - `getItem()` or square brackets (i.e. `[ ]`) can be used to select a single element out of an array or a map."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": [1, 2]\n}\n\"\"\")\n\ndisplay(events.select(col(\"a\").getItem(0).alias(\"x\")))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Using a map\nschema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n\nevents = jsonToDataFrame(\"\"\"\n{\n  \"a\": {\n    \"b\": 1\n  }\n}\n\"\"\", schema)\n\ndisplay(events.select(col(\"a\").getItem(\"b\").alias(\"x\")))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["<b>Creating a row for each array or map element</b> - `explode()` can be used to create a new row for each element in an array or each key-value pair.  This is similar to `LATERAL VIEW EXPLODE` in HiveQL."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": [1, 2]\n}\n\"\"\")\n\ndisplay(events.select(explode(\"a\").alias(\"x\")))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# Using a map\nschema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n\nevents = jsonToDataFrame(\"\"\"\n{\n  \"a\": {\n    \"b\": 1,\n    \"c\": 2\n  }\n}\n\"\"\", schema)\n\ndisplay(events.select(explode(\"a\").alias(\"x\", \"y\")))"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["<b>Collecting multiple rows into an array</b> - `collect_list()` and `collect_set()` can be used to aggregate items into an array."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n[{ \"x\": 1 }, { \"x\": 2 }]\n\"\"\")\n\ndisplay(events.select(collect_list(\"x\").alias(\"x\")))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# using an aggregation\nevents = jsonToDataFrame(\"\"\"\n[{ \"x\": 1, \"y\": \"a\" }, { \"x\": 2, \"y\": \"b\" }]\n\"\"\")\n\ndisplay(events.groupBy(\"y\").agg(collect_list(\"x\").alias(\"x\")))"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["<b>Selecting one field from each item in an array</b> - when you use dot notation on an array we return a new array where that field has been selected from each array element."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": [\n    {\"b\": 1},\n    {\"b\": 2}\n  ]\n}\n\"\"\")\n\ndisplay(events.select(\"a.b\"))"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["<b>Convert a group of columns to json</b> - `to_json()` can be used to turn structs into json strings. This method is particularly useful when you would like to re-encode multiple columns into a single one when writing data out to Kafka. This method is not presently available in SQL."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": {\n    \"b\": 1\n  }\n}\n\"\"\")\n\ndisplay(events.select(to_json(\"a\").alias(\"c\")))"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["<b>Parse a column containing json</b> - `from_json()` can be used to turn a string column with json data into a struct. Then you may flatten the struct as described above to have individual columns. This method is not presently available in SQL. \n**This method is available since Spark 2.1**"],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": \"{\\\\\"b\\\\\":1}\"\n}\n\"\"\")\n\nschema = StructType().add(\"b\", IntegerType())\ndisplay(events.select(from_json(\"a\", schema).alias(\"c\")))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["Sometimes you may want to leave a part of the JSON string still as JSON to avoid too much complexity in your schema."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": \"{\\\\\"b\\\\\":{\\\\\"x\\\\\":1,\\\\\"y\\\\\":{\\\\\"z\\\\\":2}}}\"\n}\n\"\"\")\n\nschema = StructType().add(\"b\", StructType().add(\"x\", IntegerType())\n                            .add(\"y\", StringType()))\ndisplay(events.select(from_json(\"a\", schema).alias(\"c\")))"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["<b>Parse a set of fields from a column containing json</b> - `json_tuple()` can be used to extract a fields available in a string column with json data."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n{\n  \"a\": \"{\\\\\"b\\\\\":1}\"\n}\n\"\"\")\n\ndisplay(events.select(json_tuple(\"a\", \"b\").alias(\"c\")))"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["<b>Parse a well formed string column</b> - `regexp_extract()` can be used to parse strings using regular expressions."],"metadata":{}},{"cell_type":"code","source":["events = jsonToDataFrame(\"\"\"\n[{ \"a\": \"x: 1\" }, { \"a\": \"y: 2\" }]\n\"\"\")\n\ndisplay(events.select(regexp_extract(\"a\", \"([a-z]):\", 1).alias(\"c\")))"],"metadata":{},"outputs":[],"execution_count":30}],"metadata":{"name":"Spark_SQL: Transforming Complex Data Types","notebookId":2183139256017506},"nbformat":4,"nbformat_minor":0}
