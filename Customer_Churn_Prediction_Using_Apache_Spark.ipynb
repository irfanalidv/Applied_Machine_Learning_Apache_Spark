{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"customer_churn\").getOrCreate()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["data = spark.read.csv('/FileStore/tables/Customer_Churn_Prediction/customer_churn.csv',inferSchema=True,header=True)\ndata.printSchema()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["data.show(5)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# add a column 'days_since_Onboard' until now\nfrom pyspark.sql.functions import datediff, current_date\ndata = data.withColumn(\"days_since_Onboard\",\n                       datediff(current_date(),data['Onboard_date']).alias(\"days_since_Onboard\"))\ndata.printSchema()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["data.show(5)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["data.dtypes"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["cols = []\nfor dataPoint in data.dtypes:\n    if ((dataPoint[1]=='double') or (dataPoint[1]=='int')):\n        cols.append(dataPoint[0])"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["cols"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["data_model = data.select(cols)\ndata_model.show(5)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["print('Total customers:', data_model.count())\nprint('Customers with no account manager:', data_model.filter(data_model['Account_Manager']==0).count())\nprint('Customers with account manager:', data_model.filter(data_model['Account_Manager']==1).count())"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["from pyspark.sql.functions import corr\ndata.select(corr(\"Churn\",\"Account_Manager\")).show()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["data_model = data_model.filter(data_model['Account_Manager']==0)\nprint('Customer with no account manager to use in the model:', data_model.count())\n\ndata_model.show(5)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["data_model = data_model.drop('Account_Manager')\ndata_model.show(5)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["vecCols = data_model.columns\nvecCols.remove('Churn')\nvecCols"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\nassembler = VectorAssembler(inputCols=vecCols,outputCol='features')\ndata_feed = assembler.transform(data_model).select('Churn','features')\ndata_feed.show(5)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["train_data, test_data = data_feed.randomSplit([0.7, 0.3])"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\nlogReg = LogisticRegression(featuresCol='features',labelCol='Churn')\nlogReg_trained = logReg.fit(train_data)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["logReg_trained.summary.predictions.show(5)\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["test_results = logReg_trained.transform(test_data)\n"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["test_results.show(5)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["test_results_2 = logReg_trained.evaluate(test_data)\ntest_results_2.predictions.show(5)\n"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["print(type(logReg_trained.summary))\nprint(type(test_results))\nprint(type(test_results_2))"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\nprint(\"Area under ROC:\")\nbi_eval = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='Churn', metricName='areaUnderROC')\nbi_eval.evaluate(test_results_2.predictions)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["print(\"Easier way to get Area under ROC:\")\ntest_results_2.areaUnderROC"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["print(\"Accuracy:\")\nmulti_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol='Churn',metricName='accuracy')\nmulti_eval.evaluate(test_results_2.predictions)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["logReg_trained_new = logReg.fit(data_feed)\n"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["logReg_trained_new.summary.predictions.show(5)\n"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["#Prepare new customer data\nnew_cus = spark.read.csv('/FileStore/tables/Customer_Churn_Prediction/new_customers.csv',inferSchema=True,header=True)\nnew_cus.printSchema()\n"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["new_cus.show(5)\n"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["new_cus = new_cus.withColumn(\"days_since_Onboard\",\n                       datediff(current_date(),new_cus['Onboard_date']).alias(\"days_since_Onboard\"))"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["new_cus.show(5)\n"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["from copy import deepcopy\nnew_cus_cols = deepcopy(cols)\nnew_cus_cols"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["new_cus_cols.remove('Churn')\nnew_cus_cols.remove('Account_Manager')\n"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["new_cus_cols"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["# Let's Add 'Names' column to keep track of which company will churn\nnew_cus_data = new_cus.select(['Names'] + new_cus_cols)\nnew_cus_data.show(5)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["new_cus_assembler = VectorAssembler(inputCols=new_cus_cols,outputCol='features')\nnew_cus_feed = new_cus_assembler.transform(new_cus_data).select('Names','features')\nnew_cus_feed.show()"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["#Make predictions\nnew_cus_pred = logReg_trained_new.transform(new_cus_feed)\nnew_cus_pred.show()"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["new_cus_pred.select('Names','prediction').show()\n"],"metadata":{},"outputs":[],"execution_count":38}],"metadata":{"name":"Customer_Churn_Prediction_Using_Apache_Spark","notebookId":2014520085326770},"nbformat":4,"nbformat_minor":0}
